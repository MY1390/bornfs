import scwc._
import weka.core.Instances
import weka.core.converters.ArffSaver
import weka.core.converters.ConverterUtils.DataSource
import weka.core.Instances
import weka.filters.Filter
import weka.filters.unsupervised.attribute.Remove
import scala.collection.mutable.{HashMap,HashSet,ArrayBuffer}
import scala.collection.JavaConversions._
import java.text.DecimalFormat
import java.io.File
import scopt.OptionParser

case class ARFFReader(filename: String) {
  var instances = new DataSource(filename).getDataSet

  // println
  // println("DEBUG>>")
  // println("instances.enumerateInstances = ")
  // // instances.enumerateInstances.foreach(println(_))
  // println(instances.enumerateInstances.toList(0))
  // println("<<DEBUG")

  val attr2index = HashMap[Symbol,Int]()
  val index2attr = HashMap[Int,Symbol]()
  (0 until instances.numAttributes).foreach {index =>
    attr2index += Symbol(instances.attribute(index).name) -> index
    index2attr += index -> Symbol(instances.attribute(index).name)
  }

  val numInstances  = instances.numInstances
  val numAttrs = instances.numAttributes
  val sparse_instances = sparseInstances

  def sparseInstances = {
    instances.enumerateInstances.map { instance =>
      val n = instance.numValues
      val body: ArrayBuffer[(Symbol, Int)] =
        for(i <- (0 until n - 1 ).to[ArrayBuffer]
          if instance.value(instance.index(i)).toInt != 0) yield {
          val attr_sym = Symbol(instance.attribute(instance.index(i)).name)
          Pair(attr_sym, instance.value(instance.index(i)).toInt)
        }
      val temp_sym = Symbol(instance.attribute(instance.index(n - 1)).name)
      if(temp_sym == index2attr(instances.numAttributes - 1)) {
        (body, instance.value(instance.index(n - 1)).toInt)
      } else {
        body += Pair(temp_sym, instance.value(instance.index(n - 1)).toInt)
        (body, 0)
      }
    }
  }

  // def sparseInstances = {
  //   instances.enumerateInstances.map { instance =>
  //     val n = instance.numValues
  //     val body: ArrayBuffer[(Symbol, Int)] =
  //       (0 until n - 1 ).to[ArrayBuffer].map { i:Int =>
  //         val attr_sym = Symbol(instance.attribute(instance.index(i)).name)
  //         //        attr2index(attr_sym)=i
  //         Pair(attr_sym, instance.value(instance.index(i)).toInt)
  //       }
  //     val temp_sym = Symbol(instance.attribute(instance.index(n - 1)).name)
  //     if(temp_sym == index2attr(instances.numAttributes - 1)) {
  //       (body, instance.value(instance.index(n - 1)).toInt)
  //     } else {
  //       body += Pair(temp_sym, instance.value(instance.index(n - 1)).toInt)
  //       (body, 0)
  //     }
  //   }
  // }

  def removeUnselectedAttrs(selected_attrs: List[Symbol]) {
    val remove_list =
      ((for (attr <- selected_attrs if attr != HIDDEN) yield (attr2index(attr))) ::: List(instances.numAttributes - 1)).toArray

    val filter = new Remove()
    filter.setAttributeIndicesArray(remove_list)


    filter.setInvertSelection(true)
    filter.setInputFormat(instances)
    instances = Filter.useFilter(instances, filter)
  }

  def saveArffFile (output_file_name: String) {
    val arff_saver = new ArffSaver()
    arff_saver.setInstances(instances)
    arff_saver.setFile(new File(output_file_name))
    arff_saver.writeBatch()
  }
}

object Main {

  def main(args: Array[String]) {
    // args(0): A path to an arff file
    // args(1): Selector of the measure to sort features.
    //       0: Symmetric uncertainty
    //       1: Mutual information
    //       2: Bayesian risk
    //       3: Matthew correlation coefficient
    // args(2): Threshold
    //       0: Call CWC
    //      >0: Call LCC with the specified threshold

    //val parser = new scopt.OptionParser[Config]("scopt") {}
    println("\n*** Start of CWC (Copy Rights 2015 Kilho Shin and Tetsuji Kuboyama)\n")
    print("Reading file ... ")
    val db = ARFFReader(args(0))
    val data = db.sparse_instances.to[ArrayBuffer]
    println("finished.")
    println("   # of instances:  "+db.numInstances)
    println("   # of attributes: "+db.numAttrs)
    val threshold = args(2).toDouble // 0ならCWC、正ならLCC
    val sl = args(1).toInt
    val ds = Dataset(data, sl)
    val output_file_name = args(3)

    // println("DEBUG>>")
    // println("data = ")
    // // data.foreach(println(_))
    // println(data(1))
    // println("<<DEBUG")

    val result = ds.select(threshold)

    // println("DEBUG>>")
    // println("Count the occurences of (attr_value, class_label)")
    // ds.ofc.foreach(x => println(x))
    // println("Count the occurences of attribute values")
    // ds.of.foreach(x => println(x))
    // println("Count the occurences of class labels")
    // ds.oc.foreach(x => println(x))
    // ds.displayStats(None)
    // println("The result of attribute sorting")
    // // val f = new DecimalFormat("0.00")
    // //   (0 until ds.rn.size).foreach {i =>
    // //     if(ds.nr(i) != HIDDEN)
    // //       print(ds.nr(i) + "(" + f.format(ds.msr(sl)(ds.nr(i))) + ") ")
    // //   }
    // // println
    // val f = new DecimalFormat("0.00")
    //   (0 until 30).foreach {i =>
    //     if(ds.nr(i) != HIDDEN)
    //       print(ds.nr(i) + "(" + f.format(ds.msr(sl)(ds.nr(i))) + ") ")
    //   }
    // println
    // println("<<DEBUG")


    db.removeUnselectedAttrs(result)
    db.saveArffFile(output_file_name)


    println("\nSelected attributes: feature name (score and rank in " + ds.slm(sl) + ")")
    for (attr <- result if attr!=HIDDEN) {
      print(f"$attr(${ds.msr(sl)(attr)}%.3f, ${ds.rn(attr) + 1}) ")
    }
    println
    println
    println("Statistics")
    for(x <- (0 to 3) if x != sl) {
      println("Scores in　" + ds.slm(x) + ":")
      for (attr <- result if attr!=HIDDEN) {
        print(f"$attr(${ds.msr(x)(attr)}%.3f) ")
      }
      println
    }
  }
}


